{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Métodos de Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Authors\n",
    "\n",
    "### Óscar Barquero Pérez (<oscar.barquero@urjc.es>), Carlos Figuera Pozuelo (<carlos.figuera@urjc.es>) y Rebeca Goya Esteban (<rebeca.goyaesteban@urjc.es>)\n",
    "\n",
    "### 27 de marzo de  2016\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Licencia de Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />Este obra está bajo una <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">licencia de Creative Commons Reconocimiento-NoComercial-CompartirIgual 4.0 Internacional</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1 Introducción a la práctica\n",
    "\n",
    "El objetivo de esta lab es que el alumno se familiarice con los conceptos básicos de python, en concreto de la utilización del módulo [Sklearn](http://scikit-learn.org/stable/) para resolver problemas de regresión. \n",
    "\n",
    "Este lab está organizado de la siguiente forma: en la Sección 2, se realiza una introducción más formal al proceso de regresión utilizando regresión lineal. A continuación en la Sección 3, se compararán diferentes modelos de regresión utilizando sklearn para resolver un problema de clasificación real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2 Regresión usando Regresión Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.1 Regresión Lineal\n",
    "\n",
    "Uno de los modelos de aprendizaje estadístico más simples, aunque no por ello menos potente, es el modelo de **Regresión Lineal**. \n",
    "\n",
    "Como se ha visto en clase de teoría, cuando utilizamos modelos de regresión lineal se asume que el valor de la señal que queremos estimas (predecir), que se conoce como variable respuestas u objetivo, es una combinación lineal de las variables de entrada, también conocidas como variables explicativas. En este caso, el objetivo planteado como un problema de *estimación* es obtener el valor de los coeficientes que multiplican a las variables explicativas, $w_i$. En notación matemática:\n",
    "\n",
    "$$\\hat{y}= w_0 + w_1 x_1 + ... + w_p x_p = \\mathbf{w^{T}x}$$\n",
    "\n",
    "Nomenclatura: los coeficientes $w_i$ se conocen también como pesos; es común que al coeficiencte $w_0$ se le llame *bias*.\n",
    "\n",
    "En regresión lineal se eligen los coeficientes $\\mathbf{w}$ de forma que se minimice el error cuadrático, es decir que el error entre el valor real de $y$ y el proporcionado por nuestro modelo $\\hat{y} = \\mathbf{w^{T}x}$ sea el menor posible, para todos los valores. Es decir buscamos resolver el siguiente problema de minimización:\n",
    "\n",
    "$$\\underset{w}{min\\,} {\\left|\\left| X w - y\\right|\\right|_2^2}$$\n",
    "\n",
    "Este problema de minimización se puede resolver recurriendo al, nunca suficientemente bien ponderado, *Principio de Ortogonalidad*. \n",
    "\n",
    "\n",
    "El objetivo es, pues, estimar el vector $\\mathbf{y}$ con el vector que mejor lo aproxime y que esté en el subespacio definido por las columnas de $X$, que llamaremos $\\mathbf{\\hat{y} = w^{T}x}$. Esto lo conseguimos proyectando el vector $\\mathbf{y}$ en dicho subespacio. Esto es equivalente a que el vector error, $\\mathbf{ \\varepsilon = y - \\hat{y}}$ sea ortogonal al subespacio de $X$\n",
    "\n",
    "<img src=\"./img.png\">\n",
    "\n",
    "*Gracias a la profesora Inmaculada Mora Jiménez por la figura*\n",
    "\n",
    "De esta forma, si el error es perpendicular al subespacio de $X$, sabemos que:\n",
    "\n",
    "$$X^{t}\\varepsilon = 0$$\n",
    "\n",
    "Entonces\n",
    "\n",
    "$$X^{T}\\left(\\mathbf{y} - X\\mathbf{w}\\right) \\Rightarrow X^{T}\\mathbf{y} = X^{T}X\\mathbf{w}$$\n",
    "\n",
    "Despejando los pesos:\n",
    "\n",
    "$$\\mathbf{w} = \\left(X^{T}X\\right)^{-1}X^{T}\\mathbf{y}$$\n",
    "\n",
    "Vemos que el *Principio de Ortogonalidad* nos ofrece una solución cerrada para la estimación de los pesos de nuestro modelo de regresión lineal. Culpa nuestra será, por pereza o impericia, que no seamos capaces de programar tan sencilla solución utilizando numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.2 Regresión Lineal Polinómica\n",
    "\n",
    "## Regresión Lineal con polinomios\n",
    "\n",
    "Documentación: http://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions\n",
    "\n",
    "\n",
    "El modelo de regresión lineal, tal y como se ha planteado, sólo serviría para resolver problemas en los que la relación entre la variable respuesta y las variables explicativas es lineal, tanto en los coeficientes como en las variables. Cuando existe alguna relación no lineal entre $y$ y las variables explicativas se pude extender sencillamente nuestro modelo de regresión lineal.\n",
    "\n",
    "Esta extensión es común a muchos algoritmos de aprendizaje estadístico. Esta extensión se consigue construyendo polinomios a partir de las variables explicativas (características). Así, por ejemplo, en un caso con dos variables explicativas, el modelo de regresión lineal básico sería:\n",
    "\n",
    "$$\\hat{y} = w_0 + w_1 x_1 + w_2 x_2$$\n",
    "\n",
    "Si el resutado no es un plano, sino que es un paraboloide, se puede plantear la siguiente extensión a polinomios de segundo orden:\n",
    "\n",
    "$$\\hat{y} = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1 x_2 + w_4 x_1^2 + w_5 x_2^2$$\n",
    "\n",
    "El alumno que observa por primera vez esta extensión suele pensar que ya no tratamos con un modelo lineal, pero en este punto se debe hacer notar que la linealidad está en los coeficientes, y el modelo se convierte en completamente lineal por el simple expediente de un cambio de variable:\n",
    "\n",
    "$$z = [x_1, x_2, x_1 x_2, x_1^2, x_2^2]$$\n",
    "\n",
    "Este cambio de variable nos permite reescribir el modelo de regresión lineal como:\n",
    "\n",
    "$$\\hat{y} = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5$$\n",
    "\n",
    "Como se puede observar este modelo de regresión es de la misma forma que los que hemos resuelto hasta ahora, y por lo tanto se puede resolver con las mismas técnicas. Considerando potencias más elevadas se pueden obtener modelos con una flexibilidad mucho mayor, es decir, se pueden resolver problemas en los que la relación entre la variable respuesta y las explicativas es muy compleja. Sin embargo, se corre un grave riesgo aumentando la complejidad del modelo (en este caso la complejidad es equivalente al mayor orden de polinomio), puesto que aumentamos la probabilidad de que el modelo **sobreajuste**. Más sobre esto en próximas secciones.\n",
    "\n",
    "A continuación se propone ajustar un modelo de regresión lineal con bases no lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Comparación de métodos de regresión con sklearn\n",
    "\n",
    "###  3.1 Base de datos de regresión\n",
    "\n",
    "En esta práctica vamos a utilizar la base de datos de los precios de casas en Bostón. Podéis encontrar toda la información en el repositorio de Bases de Datos para Machine Learning [UCI-Boston](http://archive.ics.uci.edu/ml/datasets/Housing)\n",
    "\n",
    "En la siguiente lista se proporciona la información de las características que se tiene por cada casa.\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. *CRIM*: per capita crime rate by town \n",
    "2. *ZN*: proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "3. *INDUS*: proportion of non-retail business acres per town \n",
    "4. *CHAS*: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "5. *NOX*: nitric oxides concentration (parts per 10 million) \n",
    "6. *RM*: average number of rooms per dwelling \n",
    "7. *AGE*: proportion of owner-occupied units built prior to 1940 \n",
    "8. *DIS*: weighted distances to five Boston employment centres \n",
    "9. *RAD*: index of accessibility to radial highways \n",
    "10. *TAX*: full-value property-tax rate per $10,000 \n",
    "11. *PTRATIO*: pupil-teacher ratio by town \n",
    "12. *B*: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "13. *LSTAT*: % lower status of the population "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Ejercicio 1. Lectura de la base de datos\n",
    "\n",
    "En este ejercicio se pide que el alumno lea la base de datos utilizando pandas. En aras de la brevedad, solo vamos a realizar la lectura del fichero csv y crear un describe del DataFrame. Se recomienda encarecidamente a los alumnos que realicen una exploración completa de la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#read data using pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"boston.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM       0\n",
      "ZN         0\n",
      "INDUS      0\n",
      "CHAS       0\n",
      "NOX        0\n",
      "RM         0\n",
      "AGE        0\n",
      "DIS        0\n",
      "RAD        0\n",
      "TAX        0\n",
      "PTRATIO    0\n",
      "B          0\n",
      "LSTAT      0\n",
      "PRICE      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.593761</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.596783</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.647422</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.593761   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.596783   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.647422   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT       PRICE  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe\n",
    "print np.sum(data.isnull()) #Usando isnull nos proporciona un booleano en caso de que tenga algun NaN, por lo que\n",
    "# si algun numero es distinto de 0 hay algun NaN\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Ejercicio 2. Separar nuestros datos en test y  training\n",
    "\n",
    "Como siempre que estemos trabajando con modelos de machine learning. El primer paso, después de haber realizado el análisis explroratorio es separar en nuestros conjunto de *test* y *training*. Cabe recordar en este punto que esta separación es obligatoria para poder reportar una estimación de la performance de nuestro modelo lo más realista posible. En el caso de disponer de un menor número de datos, se puede optar por evaluar las prestaciones de los modelos mediante un esquema de cross-validation, pero en general este último esquema produce resultados un poco más optimistas. Este tipo de particiones se pueden realizar sencillamente con sklearn [Cross-validation: evaluation estimator performance](http://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "Lo primero será obtener nuestra matrix de características $X$ y el vector respuesta $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 13)\n",
      "(152, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data[list(data)[:-1]]\n",
    "Y = data[list(data)[-1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "print X_train.shape\n",
    "print X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Ejercicio 3\n",
    "\n",
    "En este ejercicio vamos entrenar nuestro primer modelo de regresión. En este caso, igual que para clasificación, os recomiendo por comenzar con el modelo más sencillo posible: [Regresión Lineal](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html). El modelo lineal permite aumentar nuestro conocimiento sobre la naturaleza del problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-8bbd048d18d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"------------------\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "coefs = [lin_reg.intercept_]\n",
    "coefs.extend(list(lin_reg.coef_))\n",
    "\n",
    "labels = [\"bias\"]\n",
    "labels.extend(list(data)[:-1])\n",
    "\n",
    "for n,c in zip(labels, coefs):\n",
    "    print n,c(round(c, 3))\n",
    "    print \"------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Ejercicio 4\n",
    "\n",
    "En este punto vamos a realizar la evaluación del modelo. Para ello, se va a realizar la predicción de los valores de las casas sobre el conjunto de test y utilizar una métrica conveniente para regresión. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.673528086535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "#r2 score\n",
    "\n",
    "print r2_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Ejercicio 5\n",
    "\n",
    "En este punto, evolucionamos nuestro modelo y podemos utilizar modelos más complicados. Por ejemplo modelos no lineales: Vamos a compara con [SVM](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) y [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "\n",
    "Igual que hicimos en el lab sobre clasificación, vamos a tener que utilizar una estrategia de búsqueda de los hiperparámetros de los modelos. Para ello vamos a utilizar [GridSearch y cross-validation](http://scikit-learn.org/stable/modules/grid_search.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando SVM:  0.0965880270632\n",
      "Usando Random Forest:  0.81041284888\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Se hace GridSearch para modelos que tengan hiperparametros\n",
    "\n",
    "\n",
    "svm = SVR()\n",
    "busqueda = {'C':np.logspace(1, 4, 10), 'epsilon': np.logspace(-4, 1, 10)}\n",
    "gridSearch = GridSearchCV(svm, param_grid = busqueda, cv = 10, n_jobs = -1)\n",
    "gridSearch.fit(X_train, y_train) \n",
    "\n",
    "y_pred_svr = gridSearch.predict(X_test)\n",
    "print \"Usando SVM: \", r2_score(y_test, y_pred_svr) \n",
    "\n",
    "#RandomForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rand_forest = RandomForestRegressor()\n",
    "busquedaRF = {'n_estimators':[20, 50, 500]}\n",
    "gridSearch = GridSearchCV(rand_forest, param_grid = busquedaRF, cv = 10, n_jobs = -1)\n",
    "gridSearch.fit(X_train, y_train) \n",
    "\n",
    "y_pred_rf = gridSearch.predict(X_test)\n",
    "\n",
    "print \"Usando Random Forest: \", r2_score(y_test, y_pred_rf) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
